name: ğŸ”„ MacBid Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '*/30 * * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: â¬‡ï¸ Checkout repo
        uses: actions/checkout@v3

      - name: ğŸ› Debug environment before install
        run: |
          echo "package.json scripts:"
          cat package.json | jq .scripts || cat package.json
          echo "Checking .bin directory (before install):"
          ls -l node_modules/.bin || echo "No .bin yet"

      - name: ğŸ“¦ Install dependencies and Chromium
        run: |
          npm install
          npx puppeteer browsers install chrome

      - name: ğŸ” Decode credentials.json from base64
        run: echo "${{ secrets.GOOGLE_CREDENTIALS_BASE64 }}" | base64 -d > credentials.json

      - name: ğŸ“„ Create .env file
        run: echo "SHEET_ID=${{ secrets.SHEET_ID }}" >> .env

      - name: ğŸš€ Run scraper
        run: npm start
